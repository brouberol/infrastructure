#!/bin/bash

# {{ ansible_managed }}

set -eu

BLOG_DIR={{ web_home }}/blog
TMP_BLOG_CLONE=$HOME/blog-tmp
BLOG_GIT={{ git_home }}/blog.git
THEME=pelican-hss
THEME_DIR=themes/${THEME}
CSS_DIR=${THEME_DIR}/static/css


function cleanup {
    rm -rf $TMP_BLOG_CLONE
    rm -rf $BLOG_DIR/.git
}

trap cleanup EXIT

function replace {
    sed -i s/$1/$2/g $3
}

git clone $BLOG_GIT $TMP_BLOG_CLONE
cd $TMP_BLOG_CLONE

# Minify all CSS files and replace plain CSS files by their
# minify versions in the theme template
for file in $(ls -1 $CSS_DIR); do
    minified_file="$(basename "$file" .css).min.css"
    cssmin <$TMP_BLOG_CLONE/$CSS_DIR/$file > $TMP_BLOG_CLONE/$CSS_DIR/$minified_file
    replace $file $minified_file ${THEME_DIR}/templates/base.html
done
for file in $(ls -1 $CSS_DIR); do
    minified_file="$(basename "$file" .css).min.css"
    replace pygments.css pygments.min.css $TMP_BLOG_CLONE/$CSS_DIR/style.min.css
done

# Make and deploy
source {{ git_home }}/.blog.venv/bin/activate
poetry install
make html
pagefind --site output
cp -r output/* $BLOG_DIR

curl -s -X POST "https://api.darkvisitors.com/robots-txts" \
    -H "Authorization: Bearer {{ darkvisitors_api_token }}" \
    -H "Content-Type: application/json" \
    -d '{"agent_types": ["AI Data Scraper", "AI Assistant", "Undocumented AI Agent", "AI Search Crawler"], "disallow": "/"}' \
    --output $BLOG_DIR/robots.txt

# Cleanup
cd ..
cleanup
